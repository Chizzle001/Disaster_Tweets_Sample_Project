{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the neccessary Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Dataset\n",
    "\n",
    "train_df = pd.read_csv('Dataset/train.csv')\n",
    "test_df = pd.read_csv('Dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chizz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\chizz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chizz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\chizz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\chizz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# Step 2: Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Stemmer and Lemmatizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define text cleaning functions\n",
    "import re\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetical characters\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Stemming, Lemmatization, Stopword Removal\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = clean_text(text)\n",
    "    words = word_tokenize(text)\n",
    "    # Apply Lemmatization and Stemming\n",
    "    words = [lemmatizer.lemmatize(stemmer.stem(word)) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = train_df['text'].apply(preprocess_text)\n",
    "test_df['text'] = test_df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquak may allah forgiv u</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant crane hold bridg collaps nearbi home</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control wild fire california even northern par...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>utckm volcano hawaii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>polic investig ebik collid car littl portug eb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>latest home raze northern california wildfir a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0              deed reason earthquak may allah forgiv u       1  \n",
       "1                  forest fire near la rong sask canada       1  \n",
       "2     resid ask shelter place notifi offic evacu she...       1  \n",
       "3           peopl receiv wildfir evacu order california       1  \n",
       "4     got sent photo rubi alaska smoke wildfir pour ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608     two giant crane hold bridg collaps nearbi home       1  \n",
       "7609  control wild fire california even northern par...       1  \n",
       "7610                               utckm volcano hawaii       1  \n",
       "7611  polic investig ebik collid car littl portug eb...       1  \n",
       "7612  latest home raze northern california wildfir a...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquak may allah forgiv u</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant crane hold bridg collaps nearbi home</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control wild fire california even northern par...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>utckm volcano hawaii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>polic investig ebik collid car littl portug eb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>latest home raze northern california wildfir a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0              deed reason earthquak may allah forgiv u       1  \n",
       "1                  forest fire near la rong sask canada       1  \n",
       "2     resid ask shelter place notifi offic evacu she...       1  \n",
       "3           peopl receiv wildfir evacu order california       1  \n",
       "4     got sent photo rubi alaska smoke wildfir pour ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608     two giant crane hold bridg collaps nearbi home       1  \n",
       "7609  control wild fire california even northern par...       1  \n",
       "7610                               utckm volcano hawaii       1  \n",
       "7611  polic investig ebik collid car littl portug eb...       1  \n",
       "7612  latest home raze northern california wildfir a...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: N-grams (Unigrams, Bigrams, Trigrams)\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def extract_ngrams(text, n=2):\n",
    "    tokens = word_tokenize(text)\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    return [' '.join(gram) for gram in n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Adding bigrams and trigrams as features\n",
    "train_df['bigrams'] = train_df['text'].apply(lambda x: extract_ngrams(x, n=2))\n",
    "train_df['trigrams'] = train_df['text'].apply(lambda x: extract_ngrams(x, n=3))\n",
    "\n",
    "test_df['bigrams'] = test_df['text'].apply(lambda x: extract_ngrams(x, n=2))\n",
    "test_df['trigrams'] = test_df['text'].apply(lambda x: extract_ngrams(x, n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquak may allah forgiv u</td>\n",
       "      <td>1</td>\n",
       "      <td>[deed reason, reason earthquak, earthquak may,...</td>\n",
       "      <td>[deed reason earthquak, reason earthquak may, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[forest fire, fire near, near la, la rong, ron...</td>\n",
       "      <td>[forest fire near, fire near la, near la rong,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "      <td>1</td>\n",
       "      <td>[resid ask, ask shelter, shelter place, place ...</td>\n",
       "      <td>[resid ask shelter, ask shelter place, shelter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "      <td>1</td>\n",
       "      <td>[peopl receiv, receiv wildfir, wildfir evacu, ...</td>\n",
       "      <td>[peopl receiv wildfir, receiv wildfir evacu, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[got sent, sent photo, photo rubi, rubi alaska...</td>\n",
       "      <td>[got sent photo, sent photo rubi, photo rubi a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant crane hold bridg collaps nearbi home</td>\n",
       "      <td>1</td>\n",
       "      <td>[two giant, giant crane, crane hold, hold brid...</td>\n",
       "      <td>[two giant crane, giant crane hold, crane hold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control wild fire california even northern par...</td>\n",
       "      <td>1</td>\n",
       "      <td>[control wild, wild fire, fire california, cal...</td>\n",
       "      <td>[control wild fire, wild fire california, fire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>utckm volcano hawaii</td>\n",
       "      <td>1</td>\n",
       "      <td>[utckm volcano, volcano hawaii]</td>\n",
       "      <td>[utckm volcano hawaii]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>polic investig ebik collid car littl portug eb...</td>\n",
       "      <td>1</td>\n",
       "      <td>[polic investig, investig ebik, ebik collid, c...</td>\n",
       "      <td>[polic investig ebik, investig ebik collid, eb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>latest home raze northern california wildfir a...</td>\n",
       "      <td>1</td>\n",
       "      <td>[latest home, home raze, raze northern, northe...</td>\n",
       "      <td>[latest home raze, home raze northern, raze no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0              deed reason earthquak may allah forgiv u       1   \n",
       "1                  forest fire near la rong sask canada       1   \n",
       "2     resid ask shelter place notifi offic evacu she...       1   \n",
       "3           peopl receiv wildfir evacu order california       1   \n",
       "4     got sent photo rubi alaska smoke wildfir pour ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608     two giant crane hold bridg collaps nearbi home       1   \n",
       "7609  control wild fire california even northern par...       1   \n",
       "7610                               utckm volcano hawaii       1   \n",
       "7611  polic investig ebik collid car littl portug eb...       1   \n",
       "7612  latest home raze northern california wildfir a...       1   \n",
       "\n",
       "                                                bigrams  \\\n",
       "0     [deed reason, reason earthquak, earthquak may,...   \n",
       "1     [forest fire, fire near, near la, la rong, ron...   \n",
       "2     [resid ask, ask shelter, shelter place, place ...   \n",
       "3     [peopl receiv, receiv wildfir, wildfir evacu, ...   \n",
       "4     [got sent, sent photo, photo rubi, rubi alaska...   \n",
       "...                                                 ...   \n",
       "7608  [two giant, giant crane, crane hold, hold brid...   \n",
       "7609  [control wild, wild fire, fire california, cal...   \n",
       "7610                    [utckm volcano, volcano hawaii]   \n",
       "7611  [polic investig, investig ebik, ebik collid, c...   \n",
       "7612  [latest home, home raze, raze northern, northe...   \n",
       "\n",
       "                                               trigrams  \n",
       "0     [deed reason earthquak, reason earthquak may, ...  \n",
       "1     [forest fire near, fire near la, near la rong,...  \n",
       "2     [resid ask shelter, ask shelter place, shelter...  \n",
       "3     [peopl receiv wildfir, receiv wildfir evacu, w...  \n",
       "4     [got sent photo, sent photo rubi, photo rubi a...  \n",
       "...                                                 ...  \n",
       "7608  [two giant crane, giant crane hold, crane hold...  \n",
       "7609  [control wild fire, wild fire california, fire...  \n",
       "7610                             [utckm volcano hawaii]  \n",
       "7611  [polic investig ebik, investig ebik collid, eb...  \n",
       "7612  [latest home raze, home raze northern, raze no...  \n",
       "\n",
       "[7613 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Data splitting\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_df['text']\n",
    "y = train_df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4996    Courageous and honest analysis of need to use ...\n",
       " 3263    @ZachZaidman @670TheScore wld b a shame if tha...\n",
       " 4907    Tell @BarackObama to rescind medals of 'honor'...\n",
       " 2855    Worried about how the CA drought might affect ...\n",
       " 4716    @YoungHeroesID Lava Blast &amp; Power Red #Pan...\n",
       "                               ...                        \n",
       " 5226    @Eganator2000 There aren't many Obliteration s...\n",
       " 5390    just had a panic attack bc I don't have enough...\n",
       " 860     Omron HEM-712C Automatic Blood Pressure Monito...\n",
       " 7603    Officials say a quarantine is in place at an A...\n",
       " 7270    I moved to England five years ago today. What ...\n",
       " Name: text, Length: 6090, dtype: object,\n",
       " 2644    So you have a new weapon that can cause un-ima...\n",
       " 2227    The f$&amp;@ing things I do for #GISHWHES Just...\n",
       " 5448    DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...\n",
       " 132     Aftershock back to school kick off was great. ...\n",
       " 6845    in response to trauma Children of Addicts deve...\n",
       "                               ...                        \n",
       " 1835                @SmusX16475 Skype just crashed u host\n",
       " 506     Christian Attacked by Muslims at the Temple Mo...\n",
       " 3592    Man charged over fatal crash near Dubbo refuse...\n",
       " 6740    #usNWSgov Severe Weather Statement issued Augu...\n",
       " 1634    Great British &lt;b&gt;Bake&lt;/b&gt; Off's ba...\n",
       " Name: text, Length: 1523, dtype: object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: TF-IDF with N-grams\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 3))  # Using bigrams and trigrams\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Handle class imbalance using resampling\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def balance_classes(df):\n",
    "    df_majority = df[df['target'] == 1]\n",
    "    df_minority = df[df['target'] == 0]\n",
    "    df_minority_upsampled = resample(\n",
    "        df_minority,\n",
    "        replace=True,\n",
    "        n_samples=len(df_majority),\n",
    "        random_state=42\n",
    "    )\n",
    "    return pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "\n",
    "df_upsampled = balance_classes(train_df)\n",
    "X_upsampled = df_upsampled['text']\n",
    "y_upsampled = df_upsampled['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Our Deeds are the Reason of this #earthquake M...\n",
       "1                  Forest fire near La Ronge Sask. Canada\n",
       "2       All residents asked to 'shelter in place' are ...\n",
       "3       13,000 people receive #wildfires evacuation or...\n",
       "4       Just got sent this photo from Ruby #Alaska as ...\n",
       "                              ...                        \n",
       "344     **OFFICIAL VID** #TheReal &gt;&gt;&gt; https:/...\n",
       "4571    @jamienye u can't blame it all on coaching man...\n",
       "7152    This LA Startup Is So Hot that Their Flowers C...\n",
       "278     @HoneyBunzGem @primalkitchen I feel like me do...\n",
       "5847    I understand you wanting to hang out with your...\n",
       "Name: text, Length: 6542, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_upsampled, X_test_upsampled, y_train_upsampled, y_test_upsampled = train_test_split(\n",
    "    X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
    "X_train_tfidf_upsampled = tfidf.fit_transform(X_train_upsampled)\n",
    "X_test_tfidf_upsampled = tfidf.transform(X_test_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Evaluation:\n",
      "Accuracy: 0.8105\n",
      "Confusion Matrix:\n",
      "[[532 104]\n",
      " [144 529]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81       636\n",
      "           1       0.84      0.79      0.81       673\n",
      "\n",
      "    accuracy                           0.81      1309\n",
      "   macro avg       0.81      0.81      0.81      1309\n",
      "weighted avg       0.81      0.81      0.81      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "model_lr = LogisticRegression(max_iter=200)\n",
    "model_lr.fit(X_train_tfidf_upsampled, y_train_upsampled)\n",
    "y_pred_lr = model_lr.predict(X_test_tfidf_upsampled)\n",
    "# Evaluate Logistic Regression\n",
    "print(\"Logistic Regression Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_upsampled, y_pred_lr):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_upsampled, y_pred_lr)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test_upsampled, y_pred_lr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Model Evaluation:\n",
      "Accuracy: 0.7930\n",
      "Confusion Matrix:\n",
      "[[533 103]\n",
      " [168 505]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80       636\n",
      "           1       0.83      0.75      0.79       673\n",
      "\n",
      "    accuracy                           0.79      1309\n",
      "   macro avg       0.80      0.79      0.79      1309\n",
      "weighted avg       0.80      0.79      0.79      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Step 9: Support Vector Classifier (SVC)\n",
    "model_svc = SVC(kernel='linear', random_state=42)\n",
    "model_svc.fit(X_train_tfidf_upsampled, y_train_upsampled)\n",
    "y_pred_svc = model_svc.predict(X_test_tfidf_upsampled)\n",
    "\n",
    "# Evaluate SVC\n",
    "print(\"Support Vector Classifier Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_upsampled, y_pred_svc):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_upsampled, y_pred_svc)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test_upsampled, y_pred_svc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Evaluation:\n",
      "Accuracy: 0.8205\n",
      "Confusion Matrix:\n",
      "[[572  64]\n",
      " [171 502]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83       636\n",
      "           1       0.89      0.75      0.81       673\n",
      "\n",
      "    accuracy                           0.82      1309\n",
      "   macro avg       0.83      0.82      0.82      1309\n",
      "weighted avg       0.83      0.82      0.82      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_rf.fit(X_train_tfidf_upsampled, y_train_upsampled)\n",
    "y_pred_rf = model_rf.predict(X_test_tfidf_upsampled)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"Random Forest Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_upsampled, y_pred_rf):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_upsampled, y_pred_rf)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test_upsampled, y_pred_rf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ritesh - For Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from nltk import pos_tag\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import gensim.downloader as api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot for each model\n",
    "plot_confusion_matrix(y_test_upsampled, y_pred_lr, \"Logistic Regression\")\n",
    "plot_confusion_matrix(y_test_upsampled, y_pred_svc, \"Support Vector Classifier\")\n",
    "plot_confusion_matrix(y_test_upsampled, y_pred_rf, \"Random Forest\")\n",
    "\n",
    "# Step 12: Predict outcomes on test data using Random Forest Model\n",
    "new_tweets = test_df['text']\n",
    "X_test_tfidf_testing = tfidf.transform(new_tweets)\n",
    "predictions = model_rf.predict(X_test_tfidf_testing)\n",
    "\n",
    "# Display predictions\n",
    "for tweet, pred in zip(new_tweets[:10], predictions[:10]):\n",
    "    print(f\"Tweet: {tweet}\")\n",
    "    print(f\"Prediction: {'Real Disaster' if pred == 1 else 'Not Real Disaster'}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
